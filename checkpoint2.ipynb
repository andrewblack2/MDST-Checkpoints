<h1> Checkpoint:</h1>

**Looking to see completetion and effort in completing the checkpoint. It's okay if it's not correct**

Based off this dataset with school financial, enrollment, and achievement data, we are interested in what information is a useful indicator of student performance at the state level.

This question is a bit too big for a checkpoint, however. Instead, we want you to look at smaller questions related to our overall goal. Here's the overview:

1. Choose a specific test to focus on
>Math/Reading for 4/8 grade
* Pick or create features to use
>Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?
* Explore the data as it relates to that test
>Create 2 well-labeled visualizations (graphs), each with a caption describing the graph and what it tells us about the data
* Create training and testing data
>Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?
* Train a ML model to predict outcome 
>Pick if you want to do a regression or classification task. For both cases, defined _exactly_ what you want to predict, and pick any model in sklearn to use (see sklearn <a href="https://scikit-learn.org/stable/modules/linear_model.html">regressors</a> and <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">classifiers</a>).
* Summarize your findings
>Write a 1 paragraph summary of what you did and make a recommendation about if and how student performance can be predicted

** Include comments throughout your code! Every cleanup and preprocessing task should be documented.


Of course, if you're finding this assignment interesting (and we really hope you do!), you are welcome to do more than the requirements! For example, you may want to see if expenditure affects 4th graders more than 8th graders. Maybe you want to look into the extended version of this dataset and see how factors like sex and race are involved. You can include all your work in this notebook when you turn it in -- just always make sure you explain what you did and interpret your results. Good luck!
<h2> Data Cleanup </h2>

Import numpy, pandas, matplotlib, and seaborn

(Feel free to import other libraries!)
import numpy as np
import pandas as pd
import matplotlib as mpl
import seaborn as sb
Load in the "states_edu.csv" dataset and take a look at the head of the data
df = pd.read_csv("../data/states_edu.csv")
You should always familiarize yourself with what each column in the dataframe represents. \ Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project
Use this space to rename columns, deal with missing data, etc. _(optional)_
df = df.dropna()
<h2>Exploratory Data Analysis (EDA) </h2>
Chosen Outcome Variable for Test: Reading for 4th Grade

**(hit `Enter` to edit)**

Outcome Score in the questions refers to the outcome variable you chose here.
How many different years of data are in our dataset? Use a pandas function.
df["YEAR"].unique()
Let's compare Michigan to Ohio. Which state has the higher average outcome score across all years?
states = df.groupby("STATE")
michMean = df[df["STATE"] == "MICHIGAN"]["AVG_READING_4_SCORE"].mean()
ohioMean = df[df["STATE"] == "OHIO"]["AVG_READING_4_SCORE"].mean()
print ("Michigan: ", michMean)
print ("Ohio: ", ohioMean)
#states["AVG_READING_4_SCORE"].mean()

Find the average for your outcome score across all states in 2019
df["AVG_READING_4_SCORE"].mean()
Find the maximum outcome score for every state. Hint: there's a function that allows you to do this easily
states["AVG_READING_4_SCORE"].max()
<h2> Feature Selection </h2>

After exploring the data, you now have to choose features that you would use to predict the performance of the students on a chosen test (chosen outcome variable). By the way, you can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.

Use this space to modify or create features
df["INSTRUCTION_EXPENDITURE_PER_STUDENT"] = df["INSTRUCTION_EXPENDITURE"] / df["GRADES_ALL_G"]
#instructExpenditure_per_student
df["LOCAL_REVENUE_PER_STUDENT"] = df["LOCAL_REVENUE"] / df["GRADES_ALL_G"]
Final feature list: Instructional expenditure per student, state revenue per student
Feature selection justification: I think that looking at the instructional expenditure per student and the state revenue per student would help individuals understand how the amount of available money and resources affect student academic proficiency.
<h2>Visualization</h2>

Use any graph you wish to see the relationship of your chosen outcome variable with any features you chose

**Visualization 1**
import matplotlib.pyplot as plt
df.plot.scatter(x="INSTRUCTION_EXPENDITURE_PER_STUDENT", y="AVG_READING_4_SCORE")

Scatterplot showing the relationship between the instructional expenditure per student and the average 4th grade reading score.
**Visualization 2**
plt.figure(figsize=(12,12))
sb.scatterplot(data=df, x="INSTRUCTION_EXPENDITURE_PER_STUDENT", y = "LOCAL_REVENUE_PER_STUDENT", hue="AVG_READING_4_SCORE")

This is a scatterplot with three variables: the instructional expenditure per student, the local revenue per student, and the average 4th grade reading score. The average 4th grade reading score is color coded with a key in the top left corner.
<h2> Data Creation </h2>

_Use this space to create train/test data_
from sklearn.model_selection import train_test_split
X = df[['INSTRUCTION_EXPENDITURE_PER_STUDENT', 'LOCAL_REVENUE_PER_STUDENT']]
y = df['AVG_READING_4_SCORE']
X_train, X_test, y_train, y_test = train_test_split(
     X, y, test_size=0.3, random_state=0)

print(X_test)
<h2> Prediction </h2>
ML Models Resource: https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a
Chosen ML task: Classification
# import your sklearn class here
y = df.loc[X.index]['AVG_READING_4_SCORE']>220
X_train, X_test, y_train, y_test = train_test_split(
     X, y, test_size=.3, random_state=0)
from sklearn.neighbors import KNeighborsClassifier
# create your model here
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
# FOR CLASSIFICATION ONLY:
from sklearn.metrics import plot_confusion_matrix

plot_confusion_matrix(model, X_test, y_test,
                         cmap=plt.cm.Blues)
# FOR REGRESSION ONLY: (pick a single column to visualize results)

# Results from this graph _should not_ be used as a part of your results -- it is just here to help with intuition. 
# Instead, look at the error values and individual intercepts.


col_name = ??
col_index = X_train.columns.get_loc(col_name)

f = plt.figure(figsize=(12,6))
plt.scatter(X_train[col_name], y_train, color = "red")
plt.scatter(X_train[col_name], model.predict(X_train), color = "green")
plt.scatter(X_test[col_name], model.predict(X_test), color = "blue")

new_x = np.linspace(X_train[col_name].min(),X_train[col_name].max(),200)
intercept = model.predict([X_train.sort_values(col_name).iloc[0]]) - X_train[col_name].min()*model.coef_[col_index]
plt.plot(new_x, intercept+new_x*model.coef_[col_index])

plt.legend(['controlled model','true training','predicted training','predicted testing'])
plt.xlabel(col_name)
plt.ylabel(??)
<h2> Summary </h2>
**<WRITE A PARAGRAPH SUMMARIZING YOUR WORK AND FINDINGS\>**
